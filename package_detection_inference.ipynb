{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "package_detection_inference.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanmed/dw_a/blob/main/package_detection_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_Oo-5TcgNMc"
      },
      "source": [
        "!pip install -U --pre tensorflow==\"2.2.0\"\n",
        "!pip install wget\n",
        "!pip install gdown\n",
        "!pip install zipfile36"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkifBtPFgTJT"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4aj2TEmgUOn"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHl6_BaGb5wG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d97430e-2916-4c6a-ed2a-265254d91668"
      },
      "source": [
        "!pip install zipfile36\n",
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: zipfile36 in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RClQhvbddSCL"
      },
      "source": [
        "import pathlib as pl\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import cv2\n",
        "\n",
        "images_path = \"./images\"\n",
        "model_path = \"./model\"\n",
        "\n",
        "if not os.path.exists(images_path):\n",
        "  pl.Path(images_path).mkdir(parents=True, exist_ok=True)\n",
        "if not os.path.exists(model_path):\n",
        "  pl.Path(model_path).mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAMmsLbKVqXL"
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "def download_images():\n",
        "    base_url = 'https://raw.githubusercontent.com/juanmed/dw_a/main/dll_package_recognition/'\n",
        "    filenames = ['pkrecog_002_0005.jpg', 'pkrecog_003_0011.jpg', 'pkrecog_004_0010.jpg', 'pkrecog_006_0002.jpg', 'pkrecog_006_0009.jpg', 'pkrecog_006_0019.jpg', 'pkrecog_014_0011.jpg', 'pkrecog_020_0035.jpg', 'pkrecog_027_0003.jpg' , 'pkrecog_031_0006.jpg' , 'pkrecog_035_0011.jpg' ,'pkrecog_040_0016.jpg','pkrecog_045_0020.jpg']\n",
        "    image_paths = []\n",
        "    for filename in filenames:\n",
        "        image_path = tf.keras.utils.get_file(fname=filename,\n",
        "                                            origin=base_url + filename,\n",
        "                                            untar=False)\n",
        "        image_path = pathlib.Path(image_path)\n",
        "        image_paths.append(str(image_path))\n",
        "    return image_paths\n",
        "\n",
        "IMAGE_PATHS = download_images()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDABQzGWdiMJ"
      },
      "source": [
        "import shutil\n",
        "for img in IMAGE_PATHS:\n",
        "  if \".jpg\" in img:\n",
        "    shutil.move(img, \"./images/\" + img.split(\"/\")[-1])\n",
        "\n",
        "IMAGE_PATHS = os.listdir(\"./images\")\n",
        "IMAGE_PATHS = [\"./images/\" + f for f in IMAGE_PATHS if \"jpg\" in f]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owtUg1HUd9eb"
      },
      "source": [
        "IMAGE_PATHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mQorHNkYutw"
      },
      "source": [
        "for img in IMAGE_PATHS:\n",
        "  image_np = load_image_into_numpy_array(img)\n",
        "  plt.figure()\n",
        "  plt.title(img.split(\"/\")[-1])\n",
        "  plt.imshow(image_np)\n",
        "\n",
        "gt_dict = {\"pkrecog_040_0016.jpg\":\"프리노즈\",\n",
        "           \"pkrecog_006_0009.jpg\":\"씨콜드\",\n",
        "           \"pkrecog_027_0003.jpg\":\"알러엔\",\n",
        "           \"pkrecog_031_0006.jpg\":\"큐자임\",\n",
        "           \"pkrecog_020_0035.jpg\":\"알러샷\",\n",
        "           \"pkrecog_006_0002.jpg\":\"씨콜드\",\n",
        "           \"pkrecog_045_0020.jpg\":\"코란투\",\n",
        "           \"pkrecog_014_0011.jpg\":\"우루사\",\n",
        "           \"pkrecog_002_0005.jpg\":\"베아제\",\n",
        "           \"pkrecog_004_0010.jpg\":\"씨콜드\",\n",
        "           \"pkrecog_006_0019.jpg\":\"씨콜드\",\n",
        "           \"pkrecog_035_0011.jpg\":\"씨즈날\",\n",
        "           \"pkrecog_003_0011.jpg\":\"베아제\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MniiA8vFqUl6"
      },
      "source": [
        "IMAGE_PATHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2GGE48V6xDf"
      },
      "source": [
        "%%bash\n",
        "cd model\n",
        "rm -rf *"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7lIrnpEX6ZV"
      },
      "source": [
        "# Download and extract model\n",
        "import gdown\n",
        "# old, all annotations https://drive.google.com/file/d/1r3dpmqPX-Vm3bCkhoAqPOKp6574_RU9p/view?usp=sharing\n",
        "# final from Amazon Training https://drive.google.com/file/d/11QthlLdkC1u_bfzrECrKyOWSZK3gebL3/view?usp=sharing\"\n",
        "url = 'https://drive.google.com/uc?id=11QthlLdkC1u_bfzrECrKyOWSZK3gebL3'\n",
        "output = 'ssd_540x640_batch8.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi6QjDlIaq9d"
      },
      "source": [
        "import sys\n",
        "if sys.version_info >= (3, 6):\n",
        "    import zipfile\n",
        "else:\n",
        "    import zipfile36 as zipfile\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "with zipfile.ZipFile(output, 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall(model_path)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z506Ybyke_xA"
      },
      "source": [
        "import wget\n",
        "labelmap_url = \"https://raw.githubusercontent.com/juanmed/dw_a/main/dll_package_recognition/label_map.pbtxt\"\n",
        "labelmap_file = wget.download(labelmap_url)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr60zqS3f5B0"
      },
      "source": [
        "# Install COCO evaluation tools\n",
        "%%bash \n",
        "git clone https://github.com/cocodataset/cocoapi.git\n",
        "cd cocoapi/PythonAPI\n",
        "make\n",
        "cp -r pycocotools ../../models/research/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ2Nj_d7fHku",
        "outputId": "8221e5de-05f1-4725-bd51-233e9ad4fbef"
      },
      "source": [
        "import time\n",
        "import tensorflow as tf \n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = model_path + \"/my_model\" + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model...Done! Took 13.385400533676147 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_-3PpO5jQAJ"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(labelmap_file,\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy4pXnpajUS2"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import cv2\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "%matplotlib inline\n",
        "\n",
        "output_path = \"./sample_output\"\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "  pl.Path(output_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for image_path in IMAGE_PATHS[:1]:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.3,\n",
        "          agnostic_mode=False)\n",
        "\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    cv2.imwrite(os.path.join(output_path, image_path.split(\"/\")[-1]),cv2.cvtColor(image_np_with_detections, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    print('Done')\n",
        "plt.show()\n",
        "\n",
        "# sphinx_gallery_thumbnail_number = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxTbHFh9_8cN",
        "outputId": "920c614a-72f6-40bd-9364-9552fac353bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dir_name = \"/content/sample_output\"\n",
        "output_filename=\"/content/sample_output\"\n",
        "shutil.make_archive(output_filename, 'zip', dir_name)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/sample_output.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXz9vl9NF0hu"
      },
      "source": [
        "#Recognize characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bYMYNrmF9YH"
      },
      "source": [
        "%%bash\n",
        "pip install pytesseract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xps-Qfeoa2BE"
      },
      "source": [
        "%%bash\n",
        "sudo apt install tesseract-ocr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG2O4-R6a2Or"
      },
      "source": [
        "%%bash\n",
        "sudo apt install tesseract-ocr-kor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd_fuuYHa2Zi"
      },
      "source": [
        "%%bash\n",
        "sudo apt install tesseract-ocr-script-hang"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PQjrVSOGbxA"
      },
      "source": [
        "!pip install scipy imutils pytesseract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqCzrfADS3cZ"
      },
      "source": [
        "%%bash\n",
        "#pip uninstall opencv-contrib-python opencv-python -y\n",
        "#pip install opencv-contrib-python"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhWSh2WqeQTw"
      },
      "source": [
        "#hola"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzMkjkW2WIQs"
      },
      "source": [
        "#!pip install --force-reinstall opencv-contrib-python==4.1.2.30\n",
        "#!pip install --no-cache --force-reinstall opencv-contrib-python==4.0.0.21"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_y4bs4kGL6y"
      },
      "source": [
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image\n",
        "import cv2\n",
        "import pytesseract\n",
        "import imutils\n",
        "from imutils.perspective import four_point_transform\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.filters import threshold_local"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS79k3M8RPRL"
      },
      "source": [
        "# 필요한 패키지와 라이브러리를 가져옴\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 그래프에서 마이너스 폰트 깨지는 문제에 대한 대처\n",
        "mpl.rcParams['axes.unicode_minus'] = False"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BgkQVT3R0lw"
      },
      "source": [
        "%%bash\n",
        "sudo apt-get install -y fonts-nanum fonts-nanum-coding fonts-nanum-extra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofOD-m1nSBu5"
      },
      "source": [
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xz1ClA_SMV2"
      },
      "source": [
        "mpl.rc('font', family=\"NanumBarunGothic\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NkqdqSLHSokM",
        "outputId": "23edadb3-3773-44cd-97fd-520383c17912"
      },
      "source": [
        "#fm = mpl.font_manager\n",
        "mpl.get_cachedir()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.cache/matplotlib'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpbK4QrjTZdd",
        "outputId": "f40812ea-c78e-4251-aee4-76023e496b08"
      },
      "source": [
        "%%bash \n",
        "cd /root/.cache/matplotlib\n",
        "rm tex.cache"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'tex.cache': Is a directory\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jOAVewXRTm9"
      },
      "source": [
        "print ('버전: ', mpl.__version__)\n",
        "print ('설치 위치: ', mpl.__file__)\n",
        "print ('설정 위치: ', mpl.get_configdir())\n",
        "print ('캐시 위치: ', mpl.get_cachedir())\n",
        "print ('설정파일 위치: ', mpl.matplotlib_fname())\n",
        "font_list = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
        "# ttf 폰트 전체갯수\n",
        "print(len(font_list)) \n",
        "f = [f.name for f in fm.fontManager.ttflist]\n",
        "print(len(font_list))\n",
        "# 10개의 폰트명 만 출력\n",
        "f[:10]\n",
        "[(f.name, f.fname) for f in fm.fontManager.ttflist if 'Nanum' in f.name]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIITr4ggtynx"
      },
      "source": [
        "!pip install git+git://github.com/jaidedai/easyocr.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xElVPFKGhX0"
      },
      "source": [
        "from skimage.morphology import skeletonize\n",
        "from sklearn.cluster import KMeans\n",
        "import easyocr\n",
        "\n",
        "def GetLabels(data,nclust):\n",
        "    labels=[]  \n",
        "    kmeans = KMeans(n_clusters=nclust, random_state=0).fit(data)\n",
        "    means=kmeans.cluster_centers_.mean(axis=1)\n",
        "    idx = np.argsort(means)\n",
        "    lut = np.zeros_like(idx)\n",
        "    lut[idx] = np.arange(nclust)\n",
        "    for i in range(len(kmeans.labels_)):\n",
        "        labels.append(lut[kmeans.labels_[i]])\n",
        "    return (labels,np.sort(means))\n",
        "\n",
        "def get_image_crop(image, xmin_n, ymin_n, xmax_n, ymax_n, margin_x=0, margin_y=0):\n",
        "  h,w,d = image.shape\n",
        "  xmin = int(xmin_n * w)\n",
        "  ymin = int(ymin_n * h)\n",
        "  xmax = int(xmax_n * w)\n",
        "  ymax = int(ymax_n * h)\n",
        "  return image[ymin - margin_y: ymax + margin_y, xmin - margin_x: xmax + margin_x]\n",
        "\n",
        "w = []\n",
        "h = []\n",
        "for ind, image_path in enumerate(IMAGE_PATHS[:1]):\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path))\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "    detections = detect_fn(input_tensor)\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    for i,(box,cl,score) in enumerate(zip(detections['detection_boxes'],detections['detection_classes'],detections['detection_scores'])):\n",
        "      if score > 0.3:\n",
        "        if cl == 100: #is char\n",
        "          title_crop = get_image_crop(image_np_with_detections,box[1],box[0],box[3],box[2], 16, 0)\n",
        "          title_crop = (skeletonize(cv2.cvtColor(title_crop, cv2.COLOR_RGB2GRAY)//255) * 255).astype(np.uint8)\n",
        "          for i in range(4):\n",
        "            plt.figure()\n",
        "            recog_res = pytesseract.image_to_string(title_crop, lang='kor', config='-psm 8')\n",
        "            print(recog_res)\n",
        "            #plt.title(image_path.split(\"/\")[-1] + \", \" + str(i))\n",
        "            plt.title(recog_res)\n",
        "            #print(image_path.split(\"/\")[-1] + \", \" + str(i) + \", \" + recog_res)\n",
        "            plt.imshow(title_crop)\n",
        "            title_crop=cv2.rotate(title_crop, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "        if cl == 5: #is title\n",
        "          title_crop = get_image_crop(image_np_with_detections,box[1],box[0],box[3],box[2], 16, 16)\n",
        "\n",
        "          \n",
        "          #top,bottom,left,right=(1,1,1,1)\n",
        "          #title_crop\t=\tcv2.copyMakeBorder(\ttitle_crop, top, bottom, left, right, cv2.BORDER_CONSTANT,value=1\t)\n",
        "          if title_crop.shape[0] > title_crop.shape[1]:\n",
        "            title_crop=cv2.rotate(title_crop, cv2.ROTATE_90_CLOCKWISE)\n",
        "          #title_crop = (skeletonize(cv2.cvtColor(title_crop, cv2.COLOR_RGB2GRAY)//255) * 255).astype(np.uint8)\n",
        "          show = True\n",
        "          #w.append(title_crop.shape[1])\n",
        "          #h.append(title_crop.shape[0])\n",
        "          dim = (380,160)\n",
        "          title_crop = cv2.resize(title_crop, dim, interpolation = cv2.INTER_AREA)\n",
        "          if(show):          \n",
        "            plt.figure()\n",
        "            plt.title(\"Original\")\n",
        "            plt.imshow(title_crop)\n",
        "\n",
        "          \n",
        "          title_crop = cv2.bilateralFilter(title_crop,9,75,75)\n",
        "          if(show):          \n",
        "            plt.figure()\n",
        "            plt.title(\"Bilateral Filtered\")\n",
        "            plt.imshow(title_crop, cmap=\"gray\")\n",
        "\n",
        "          canny_edge = cv2.Canny(title_crop,75,200).astype(np.uint8)\n",
        "          canny_edge = cv2.dilate(canny_edge, kernel=np.ones((3,3), np.uint8), iterations=2)\n",
        "          #find contours\n",
        "          if(show):\n",
        "            plt.figure()\n",
        "            plt.title(\"Canny\")\n",
        "            plt.imshow(canny_edge, cmap=\"gray\")\n",
        "\n",
        "          contours2, hierarchy = cv2.findContours(canny_edge, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
        "          print(\"hierarchy\",hierarchy.shape)\n",
        "          sorted_cnts = sorted(contours2, key=cv2.contourArea)\n",
        "          areas = np.array([cv2.contourArea(c) for c in contours2])\n",
        "          kmeans = KMeans(n_clusters=2, random_state=0).fit(areas.reshape(-1,1))\n",
        "          means = kmeans.cluster_centers_.mean(axis=1)\n",
        "          #print(means)\n",
        "          #print(kmeans.labels_)\n",
        "          contours = contours2 #[c  for (c, label) in zip(contours, kmeans.labels_) if (label == 1)]\n",
        "\n",
        "          if(show):\n",
        "            plt.figure()\n",
        "            plt.hist(areas,bins=4)\n",
        "          # draw moments\n",
        "          for c in contours:\n",
        "            M = cv2.moments(c)\n",
        "            if M[\"m00\"] == 0:\n",
        "              M[\"m00\"] = 0.1\n",
        "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "            title_crop\t=\tcv2.circle(title_crop, (cX,cY), 3, (0,255,0),-1)\n",
        "\n",
        "          if(show):\n",
        "            plt.figure()\n",
        "            plt.title(\"Original\")\n",
        "            plt.imshow(title_crop, cmap=\"gray\")\n",
        "\n",
        "          img_contours = np.zeros(canny_edge.shape)\n",
        "          i = -1\n",
        "          #for i in range(len(kmeans.labels_)):\n",
        "          #if kmeans.labels_[i] == 1 and (hierarchy[0][i][-1] == -1):\n",
        "          img_contours = cv2.drawContours(img_contours, contours, i, (255,255,255), -1, hierarchy=hierarchy, maxLevel = 1)\n",
        "          img_contours = np.logical_not(img_contours).astype(np.uint8) # invert colors\n",
        "\n",
        "          if(show):\n",
        "            plt.figure()\n",
        "            plt.title(\"Contours\")\n",
        "            plt.imshow(img_contours, cmap=\"gray\")\n",
        "\n",
        "          #img_fill = np.zeros(img_contours.shape)\n",
        "          #cv2.fillPoly(img_fill, contours, (255,255,255))\n",
        "          #plt.figure()\n",
        "          #plt.title(\"Polygon Fill\")\n",
        "          #plt.imshow(img_fill, cmap=\"gray\")\n",
        "\n",
        "          #title_crop = (skeletonize(img_contours//255) * 255).astype(np.uint8)\n",
        "          #title_crop = cv2.dilate(title_crop, kernel=np.ones((3,3), np.uint8), iterations=3)\n",
        "\n",
        "          for i in range(2):\n",
        "            plt.figure()\n",
        "            recog_res = pytesseract.image_to_string(img_contours, lang='kor', config='-psm 8')\n",
        "            print(recog_res.replace(\"\\n\",\"_\"))\n",
        "            image_file = image_path.split(\"/\")[-1]\n",
        "            if gt_dict[image_file] in recog_res:\n",
        "              print(\"** EXITO **\")\n",
        "            reader = easyocr.Reader(['ko','en'], gpu=False) # need to run only once to load model into memory\n",
        "            result = reader.readtext(title_crop)\n",
        "            print(result)\n",
        "            #plt.title(image_path.split(\"/\")[-1] + \", \" + str(i))\n",
        "            plt.title(\" Prueba {}\".format(i))\n",
        "            #print(image_path.split(\"/\")[-1] + \", \" + str(i) + \", \" + recog_res)\n",
        "            plt.imshow(img_contours, cmap=\"gray\")\n",
        "            img_contours=cv2.flip(img_contours, -1)\n",
        "          #cv2.imwrite(os.path.join(output_path, image_path.split(\"/\")[-1]),cv2.cvtColor(image_np_with_detections, cv2.COLOR_RGB2BGR))\n",
        "    print('Done')\n",
        "plt.show()\n",
        "\n",
        "# sphinx_gallery_thumbnail_number = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r42SlE9g0KXN"
      },
      "source": [
        "# Measure Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVEmsbgf0M6-"
      },
      "source": [
        "acc_path = \"./acc_images\"\n",
        "\n",
        "if not os.path.exists(acc_path):\n",
        "  pl.Path(acc_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download and extract model\n",
        "# old, all annotations https://drive.google.com/file/d/1r3dpmqPX-Vm3bCkhoAqPOKp6574_RU9p/view?usp=sharing\n",
        "# final from Amazon Training https://drive.google.com/file/d/1bUTdEV0ZfEie1ZKS_uXhHyjyUa-ouqBt/view?usp=sharing\"\n",
        "url = 'https://drive.google.com/uc?id=1bUTdEV0ZfEie1ZKS_uXhHyjyUa-ouqBt'\n",
        "output = 'acc_images.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y804Bzp8Pzs0"
      },
      "source": [
        "!unzip acc_images.zip > /dev/null"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LM4YyuHQhk8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "img_dir = 'dataset_amazon_2'\n",
        "\n",
        "IMAGE_PATHS = os.listdir(img_dir)\n",
        "IMAGE_PATHS = [f for f in IMAGE_PATHS if '.jpg' in f]\n",
        "\n",
        "gt_labels =  pd.read_csv(os.path.join(img_dir, 'image_names.csv'), index_col= 0)\n",
        "\n",
        "tess_success = 0\n",
        "easy_success = 0\n",
        "\n",
        "for ind, image_path in enumerate(IMAGE_PATHS[:10]):\n",
        "    print(\"Processing: {}\".format(image_path))\n",
        "    image_np = load_image_into_numpy_array(os.path.join(img_dir, image_path))\n",
        "    data = gt_labels[gt_labels['files']==image_path]['names'].tolist()[0]\n",
        "    for i in range(3):\n",
        "      #print(\"Rotation \",i)\n",
        "      recog_res = pytesseract.image_to_string(image_np, lang='kor', config='-psm 8')\n",
        "      if data in recog_res:\n",
        "        tess_success = tess_success + 1\n",
        "      reader = easyocr.Reader(['ko','en'], gpu=True) # need to run only once to load model into memory\n",
        "      result = reader.readtext(image_np)\n",
        "      for detection in result:\n",
        "        points, text, score = detection\n",
        "        if data in text:\n",
        "          easy_success = easy_success +1\n",
        "      image_np=cv2.rotate(image_np, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "print(\"Tesseract: {}/{}\".format(tess_success,len(IMAGE_PATHS)))\n",
        "print(\"EasyOCR: {}/{}\".format(easy_success,len(IMAGE_PATHS)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2oDO0WkZYcM",
        "outputId": "09fe4e86-c5eb-44d0-bfc9-02c548245670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text = \"\"\n",
        "for el in np.unique(gt_labels['names']):\n",
        "  text = text+\"'\"+el+\"'\" + \",\"\n",
        "print(text)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'그날엔노즈플러스','그란엔노즈','그린노즈에스','래피노즈','래피콜','래피콜노즈','레피콜','베아제','소하자임','속시판','속코','시노카엔','시노타딘','시로제노','쎄르텍','씨콜드','알러샷','알러엔','알러지성 바염 코감기','알러지성 비염 코감기','알러지성 비염 코기','알리지성 비염 코감기','알지싹로라','오로친','우라사','이지엔5이브','이지엔6','이지엔6애니','이지엔6에이스','이지엔6이브','이지엔6프로','이지엔6프로이지엔6프로','지르텍','코드랍','코란투에스','코린투에스','코메키나','코미','코스펜','코졸텍','큐자임','클라리틴','클라리틴정','프노즈','프리노즈',\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo6pWriPGhat"
      },
      "source": [
        "from difflib import SequenceMatcher\n",
        "tess_success0 = 0\n",
        "easy_success0 = 0\n",
        "\n",
        "tess_success1 = 0\n",
        "easy_success1 = 0\n",
        "\n",
        "tess_success2 = 0\n",
        "easy_success2 = 0\n",
        "\n",
        "tess_success3 = 0\n",
        "easy_success3 = 0\n",
        "\n",
        "tess_success4 = 0\n",
        "easy_success4 = 0\n",
        "\n",
        "tess_success5 = 0\n",
        "easy_success5 = 0\n",
        "\n",
        "tess_rates = []\n",
        "easy_rates = []\n",
        "\n",
        "def compare_strings(a,b):\n",
        "  return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "thresh0 = 0.25\n",
        "thresh1 = 0.50\n",
        "thresh2 = 0.75\n",
        "thresh3 = 0.90\n",
        "thresh4 = 0.95\n",
        "thresh5 = 0.99\n",
        "\n",
        "for ind, image_path in enumerate(IMAGE_PATHS[:]):\n",
        "    print(\"Processing: {}\".format(image_path), end=\" \")\n",
        "    image_np = load_image_into_numpy_array(os.path.join(img_dir, image_path))\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "    detections = detect_fn(input_tensor)\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "\n",
        "    for i,(box,cl,score) in enumerate(zip(detections['detection_boxes'],detections['detection_classes'],detections['detection_scores'])):\n",
        "      if score > 0.3:\n",
        "        if cl == 100: #is char\n",
        "          title_crop = get_image_crop(image_np_with_detections,box[1],box[0],box[3],box[2], 16, 0)\n",
        "          for i in range(4):\n",
        "            plt.figure()\n",
        "            recog_res = pytesseract.image_to_string(title_crop, lang='kor', config='-psm 8')\n",
        "            print(recog_res)\n",
        "            plt.title(recog_res)\n",
        "            plt.imshow(title_crop)\n",
        "            title_crop=cv2.rotate(title_crop, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "        if cl == 5: #is title\n",
        "          title_crop = get_image_crop(image_np_with_detections,box[1],box[0],box[3],box[2], 16, 16)\n",
        "          gtlabel = gt_labels[gt_labels['files']==image_path]['names'].tolist()[0]\n",
        "          #print(data)\n",
        "\n",
        "          if title_crop.shape[0] > title_crop.shape[1]:\n",
        "            title_crop=cv2.rotate(title_crop, cv2.ROTATE_90_CLOCKWISE)\n",
        "          show = False\n",
        "\n",
        "          dim = (380,160)\n",
        "          title_crop = cv2.resize(title_crop, dim, interpolation = cv2.INTER_AREA)\n",
        "          if(show):          \n",
        "            plt.figure()\n",
        "            plt.title(image_path+\", \"+gtlabel)\n",
        "            plt.imshow(title_crop)\n",
        "\n",
        "          for i in range(2):\n",
        "            recog_res = pytesseract.image_to_string(title_crop, lang='kor', config='-psm 8')\n",
        "            recog_res = recog_res.replace(\" \",\"\",-1).replace(\"\\n\",\"/\",-1)\n",
        "            #print(\"Tesseract: \")\n",
        "            score = compare_strings(gtlabel,recog_res)\n",
        "            if score > thresh0:\n",
        "              tess_success0 += 1\n",
        "            if score > thresh1:\n",
        "              tess_success1 += 1\n",
        "            if score > thresh2:\n",
        "              tess_success2 += 1\n",
        "            if score > thresh3:\n",
        "              tess_success3 += 1\n",
        "            if score > thresh4:\n",
        "              tess_success4 += 1\n",
        "            if score > thresh5:\n",
        "              tess_success5 += 1\n",
        "            tess_rates.append(score)\n",
        "            \n",
        "            reader = easyocr.Reader(['ko','en'], gpu=True) # need to run only once to load model into memory\n",
        "            result = reader.readtext(title_crop)\n",
        "            #print(\"EasyOCR: \",end=\"\")\n",
        "            for detection in result:\n",
        "              points, text, score = detection\n",
        "              score = compare_strings(gtlabel,text)\n",
        "              if score > thresh0:\n",
        "                easy_success0 += 1\n",
        "              if score > thresh1:\n",
        "                easy_success1 += 1\n",
        "              if score > thresh2:\n",
        "                easy_success2 += 1\n",
        "              if score > thresh3:\n",
        "                easy_success3 += 1\n",
        "              if score > thresh4:\n",
        "                easy_success4 += 1\n",
        "              if score > thresh5:\n",
        "                easy_success5 += 1\n",
        "              easy_rates.append(score)\n",
        "            #print()\n",
        "\n",
        "            title_crop=cv2.flip(title_crop, -1)\n",
        "\n",
        "    print('Done')\n",
        "\n",
        "tess_rate = tess_success0/len(IMAGE_PATHS)\n",
        "easy_rate = easy_success0/len(IMAGE_PATHS)\n",
        "print(\"Tesseract0: {}/{} = {:.4f}\".format(tess_success0,len(IMAGE_PATHS),tess_rate))\n",
        "print(\"EasyOCR0: {}/{} = {:.4f}\".format(easy_success0,len(IMAGE_PATHS),easy_rate))\n",
        "\n",
        "tess_rate = tess_success1/len(IMAGE_PATHS)\n",
        "easy_rate = easy_success1/len(IMAGE_PATHS)\n",
        "print(\"Tesseract1: {}/{} = {:.4f}\".format(tess_success1,len(IMAGE_PATHS),tess_rate))\n",
        "print(\"EasyOCR1: {}/{} = {:.4f}\".format(easy_success1,len(IMAGE_PATHS),easy_rate))\n",
        "\n",
        "tess_rate = tess_success2/len(IMAGE_PATHS)\n",
        "easy_rate = easy_success2/len(IMAGE_PATHS)\n",
        "print(\"Tesseract2: {}/{} = {:.4f}\".format(tess_success2,len(IMAGE_PATHS),tess_rate))\n",
        "print(\"EasyOCR2: {}/{} = {:.4f}\".format(easy_success2,len(IMAGE_PATHS),easy_rate))\n",
        "\n",
        "tess_rate = tess_success3/len(IMAGE_PATHS)\n",
        "easy_rate = easy_success3/len(IMAGE_PATHS)\n",
        "print(\"Tesseract3: {}/{} = {:.4f}\".format(tess_success3,len(IMAGE_PATHS),tess_rate))\n",
        "print(\"EasyOCR3: {}/{} = {:.4f}\".format(easy_success3,len(IMAGE_PATHS),easy_rate))\n",
        "\n",
        "tess_rate = tess_success4/len(IMAGE_PATHS)\n",
        "easy_rate = easy_success4/len(IMAGE_PATHS)\n",
        "print(\"Tesseract4: {}/{} = {:.4f}\".format(tess_success4,len(IMAGE_PATHS),tess_rate))\n",
        "print(\"EasyOCR4: {}/{} = {:.4f}\".format(easy_success4,len(IMAGE_PATHS),easy_rate))\n",
        "\n",
        "tess_rate = tess_success5/len(IMAGE_PATHS)\n",
        "easy_rate = easy_success5/len(IMAGE_PATHS)\n",
        "print(\"Tesseract5: {}/{} = {:.4f}\".format(tess_success5,len(IMAGE_PATHS),tess_rate))\n",
        "print(\"EasyOCR5: {}/{} = {:.4f}\".format(easy_success5,len(IMAGE_PATHS),easy_rate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwOnfn1kGhc-"
      },
      "source": [
        "for i in [0,0.25,0.5,0.75,0.9]:\n",
        "  q = np.quantile(tess_rates,q=i)\n",
        "  print(i,q)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoILmz0aGhhI"
      },
      "source": [
        "c = 0\n",
        "for d in easy_rates:\n",
        "  if d > 0.3:\n",
        "    c += 1\n",
        "\n",
        "print(c,len(easy_rates))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X7ZHBQknxyt"
      },
      "source": [
        "# Evaluate model\n",
        "import pathlib as pl\n",
        "\n",
        "training_path = \"./workspace/training_demo\"\n",
        "annotations_path = \"./annotations\"\n",
        "\n",
        "if not os.path.exists(training_path+\"/images/train\"):\n",
        "  pl.Path(training_path+\"/images/train\").mkdir(parents=True, exist_ok=True)\n",
        "if not os.path.exists(training_path+\"/test\"):\n",
        "  pl.Path(training_path+\"/images/test\").mkdir(parents=True, exist_ok=True)\n",
        "if not os.path.exists(annotations_path):\n",
        "  pl.Path(annotations_path).mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y_xwAvFoH5I"
      },
      "source": [
        "import wget\n",
        "dataset_partition_url = \"https://raw.githubusercontent.com/juanmed/dw_a/main/dll_package_recognition/dataset_partition.py\"\n",
        "dataset_partition_file = wget.download(dataset_partition_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2LTxBlHoCo-"
      },
      "source": [
        "# get images\n",
        "#images_url = \"https://drive.google.com/file/d/1aXYKA0_-flbqhUfzU8Z7uoB33hvVn-DJ/view?usp=sharing\"\n",
        "import gdown\n",
        "import shutil\n",
        "url = 'https://drive.google.com/uc?id=1aXYKA0_-flbqhUfzU8Z7uoB33hvVn-DJ'\n",
        "output = 'image_pack.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "shutil.move(output, training_path+\"/images/\"+output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baWSvrUloUI0"
      },
      "source": [
        "import sys\n",
        "if sys.version_info >= (3, 6):\n",
        "    import zipfile\n",
        "else:\n",
        "    import zipfile36 as zipfile\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "with zipfile.ZipFile(training_path+\"/images/\"+output, 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall(training_path+\"/images/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S5mmbV7oXWz"
      },
      "source": [
        "# Partition the dataset\n",
        "%%bash\n",
        "python dataset_partition.py -x -i \"./workspace/training_demo/images/pkrecog_006\" -o \"./workspace/training_demo/images/\" -r 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdestuq9od_e"
      },
      "source": [
        "gen_tf_url = \"https://raw.githubusercontent.com/juanmed/dw_a/main/dll_package_recognition/generate_tfrecord.py\"\n",
        "wget.download(gen_tf_url)\n",
        "anno_path = \"./workspace/training_demo/annotations\"\n",
        "if not os.path.exists(anno_path):\n",
        "  pl.Path(anno_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "shutil.move(labelmap_file, anno_path+\"/\"+labelmap_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UXNl1qApShA"
      },
      "source": [
        "# Generate .record files\n",
        "%%bash\n",
        "python generate_tfrecord.py -x ./workspace/training_demo/images/train -l ./workspace/training_demo/annotations/label_map.pbtxt -o ./workspace/training_demo/annotations/train.record\n",
        "python generate_tfrecord.py -x ./workspace/training_demo/images/test -l ./workspace/training_demo/annotations/label_map.pbtxt -o ./workspace/training_demo/annotations/test.record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCLF0owRrS0V"
      },
      "source": [
        "net_name = \"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\"\n",
        "config_url = \"https://raw.githubusercontent.com/juanmed/dw_a/main/dll_package_recognition/{}.config\".format(net_name)\n",
        "config_file = wget.download(config_url)\n",
        "\n",
        "shutil.move(config_file, model_path + \"/\" + config_file)\n",
        "shutil.copy(\"./models/research/object_detection/model_main_tf2.py\",\"./workspace/training_demo/model_main_tf2.py\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InX6nkZXqkda"
      },
      "source": [
        "# Start evaluation\n",
        "%%bash\n",
        "cd workspace/training_demo/\n",
        "python model_main_tf2.py --alsologtostderr --model_dir=models/my_model --pipeline_config_path=model/my_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config --checkpoint_dir=model/my_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBTqODJSPkSx"
      },
      "source": [
        "title_crop.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpgtt3duPlb5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}